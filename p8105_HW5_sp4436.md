p8105_hw5_sp4436
================
Sukhman Parhar
2025-11-15

``` r
library(tidyverse)
```

    ## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
    ## ✔ dplyr     1.1.4     ✔ readr     2.1.5
    ## ✔ forcats   1.0.1     ✔ stringr   1.5.2
    ## ✔ ggplot2   4.0.0     ✔ tibble    3.3.0
    ## ✔ lubridate 1.9.4     ✔ tidyr     1.3.1
    ## ✔ purrr     1.1.0     
    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()
    ## ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors

``` r
library(readxl)
library(haven)
library(readr)
library(p8105.datasets)
library(ggridges)
library(dplyr)
library(janitor)
```

    ## 
    ## Attaching package: 'janitor'
    ## 
    ## The following objects are masked from 'package:stats':
    ## 
    ##     chisq.test, fisher.test

``` r
library(patchwork)
library(broom)

set.seed(1)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Problem 1

``` r
bday_sim = function(n_room) {
  
  birthdays = sample(1:365, n_room, replace = TRUE)
  
  repeated_bday = length(unique(birthdays)) < n_room
  
  repeated_bday
}

bday_sim(20)
```

    ## [1] FALSE

``` r
bday_results = 
  expand_grid(
    group_size = 2:50,
    iter = 1:10000
  ) |> 
  mutate(
    result = map_lgl(group_size, bday_sim)
  ) |> 
  group_by(group_size) |> 
  summarize(
    prob_repeat = mean(result)
  )
```

``` r
bday_results |> 
  ggplot(aes(x = group_size, y = prob_repeat)) + 
  geom_point() + 
  geom_line()
```

<img src="p8105_HW5_sp4436_files/figure-gfm/Probability Plot-1.png" width="90%" />

The probability of observing at least one shared birthday increases
nonlinearly as group size grows. It is nearly zero for small groups
(fewer than 10 people), but it rises quickly afterward. Around 20–25
people the probability exceeds 50%, and by 40 people it is above 90%.

## Problem 2

``` r
sim_one_sample = function(n = 30, true_mu = 0, true_sigma = 5) {
  
#Simulate data
  x = rnorm(n, mean = true_mu, sd = true_sigma)
  
#One-sample t-test of H0: mu = 0
  test_result = t.test(x, mu = 0)
  
#Return estimate + p-value
  broom::tidy(test_result) |>
    select(estimate, p.value)
}
```

``` r
sim_results = 
  expand_grid(
    true_mu = 0:6,
    iter = 1:5000
  ) |>
  mutate(
    output = map(true_mu, ~ sim_one_sample(true_mu = .x))
  ) |>
  unnest(output)

sim_results
```

    ## # A tibble: 35,000 × 4
    ##    true_mu  iter estimate p.value
    ##      <int> <int>    <dbl>   <dbl>
    ##  1       0     1  -0.341   0.698 
    ##  2       0     2   0.0128  0.990 
    ##  3       0     3   0.785   0.373 
    ##  4       0     4  -0.435   0.690 
    ##  5       0     5  -1.71    0.0717
    ##  6       0     6   0.314   0.695 
    ##  7       0     7   0.431   0.645 
    ##  8       0     8   1.60    0.0934
    ##  9       0     9   1.50    0.167 
    ## 10       0    10   1.20    0.248 
    ## # ℹ 34,990 more rows

``` r
power_summary = sim_results |>
  mutate(true_mu = as.numeric(true_mu)) |>
  group_by(true_mu) |>
  summarize(power = mean(p.value < 0.05))

power_summary |>
  ggplot(aes(x = true_mu, y = power)) +
  geom_line(linewidth = 1.2, color = "blue") +
  geom_point(size = 3, color = "blue") +

  #Type I error reference line
  geom_hline(yintercept = 0.05, linetype = "longdash", color = "red", linewidth = 1.1) +

  #80% power reference line
  geom_hline(yintercept = 0.80, linetype = "longdash", color = "purple", linewidth = 1.1) +

  labs(
    title = "Statistical Power vs. Effect Size",
    subtitle = "Based on 5,000 simulations per group (n = 30)",
    x = "True Value of μ (Effect Size)",
    y = "Proportion of Times H₀ Rejected (Power)"
  ) +
  theme_minimal()
```

<img src="p8105_HW5_sp4436_files/figure-gfm/Power Plots-1.png" width="90%" />

Power increases monotonically as the true mean moves further from 0.
When μ = 0, the rejection rate is approximately 0.05, matching the
expected Type I error rate. As μ increases, the null hypothesis becomes
increasingly false, and the probability of rejection rises sharply,
exceeding 80% once μ is large enough relative to the noise.

``` r
#Average estimate across all simulations
avg_estimate =
  sim_results |>
  group_by(true_mu) |>
  summarize(mean_estimate = mean(estimate))

#Average estimate conditional on rejection
avg_estimate_reject =
  sim_results |>
  mutate(reject = p.value < 0.05) |>
  group_by(true_mu) |>
  summarize(mean_estimate_reject = mean(estimate[reject]))

#Combine both
combined =
  avg_estimate |>
  left_join(avg_estimate_reject, by = "true_mu")

#Overlay
combined |>
  ggplot(aes(x = true_mu)) +
  
  #Unconditional mean (black)
  geom_line(aes(y = mean_estimate),
            color = "black", linewidth = 1.2) +
  geom_point(aes(y = mean_estimate),
             color = "black", size = 3) +
  
  #Conditional-on-rejection mean (purple)
  geom_line(aes(y = mean_estimate_reject),
            color = "purple", linewidth = 1.2) +
  geom_point(aes(y = mean_estimate_reject),
             color = "purple", size = 3) +
  
  labs(
    title = "Average Estimate of μ vs True μ",
    subtitle = "Black: overall mean estimate; Purple: mean estimate among rejections",
    x = "True μ",
    y = "Average estimate of μ̂"
  ) +
  theme_minimal()
```

<img src="p8105_HW5_sp4436_files/figure-gfm/mu plots-1.png" width="90%" />

The black line shows that the sample mean is an unbiased estimator:
across all simulations, the average estimate closely matches the true
value of μ. The purple line, which conditions on rejection, is biased
upward when μ is small — only extreme positive samples lead to
significance when the true effect is near zero. As μ grows and power
increases, the conditional and unconditional estimates converge, because
nearly all samples reject the null.

## Problem 3

``` r
homicide_df = 
  read_csv("https://raw.githubusercontent.com/washingtonpost/data-homicides/master/homicide-data.csv") |>
  mutate(
    city_state = str_c(city, ", ", state),
    unsolved = disposition %in% c("Closed without arrest", "Open/No arrest")
  )
```

    ## Rows: 52179 Columns: 12
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (9): uid, victim_last, victim_first, victim_race, victim_age, victim_sex...
    ## dbl (3): reported_date, lat, lon
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

This dataset contains 14 columns and 52179 rows. Each row represents a
single homicide and includes victim demographics, the incident date,
location (city and state), and case disposition. Cities vary widely in
the proportion of unsolved homicides, with some cities showing much
higher unsolved rates than others.

``` r
city_summary = homicide_df |>
  mutate(city_state = str_c(city, ", ", state)) |>
  group_by(city_state) |>
  summarize(
    total_homicides = n(),
    unsolved_homicides = sum(unsolved)
  )

print(city_summary)
```

    ## # A tibble: 51 × 3
    ##    city_state      total_homicides unsolved_homicides
    ##    <chr>                     <int>              <int>
    ##  1 Albuquerque, NM             378                146
    ##  2 Atlanta, GA                 973                373
    ##  3 Baltimore, MD              2827               1825
    ##  4 Baton Rouge, LA             424                196
    ##  5 Birmingham, AL              800                347
    ##  6 Boston, MA                  614                310
    ##  7 Buffalo, NY                 521                319
    ##  8 Charlotte, NC               687                206
    ##  9 Chicago, IL                5535               4073
    ## 10 Cincinnati, OH              694                309
    ## # ℹ 41 more rows

``` r
# Filter for Baltimore
baltimore_data = city_summary |>
  filter(city_state == "Baltimore, MD")

# Run proportion test using total + unsolved
bal_prop_test = with(baltimore_data, {
  prop.test(
    x = unsolved_homicides, 
    n = total_homicides
  )
})

# Tidy output
bal = broom::tidy(bal_prop_test)

bal
```

    ## # A tibble: 1 × 8
    ##   estimate statistic  p.value parameter conf.low conf.high method    alternative
    ##      <dbl>     <dbl>    <dbl>     <int>    <dbl>     <dbl> <chr>     <chr>      
    ## 1    0.646      239. 6.46e-54         1    0.628     0.663 1-sample… two.sided

``` r
# For each city, run a prop.test using unsolved_homicides and total_homicides
city_tests =
  city_summary |>
  mutate(
    prop_tests = map2(
      unsolved_homicides,
      total_homicides,
      ~ prop.test(x = .x, n = .y)
    ),
    
    tidy_results = map(prop_tests, broom::tidy)
  ) |>
  unnest(tidy_results) |>
  select(city_state, estimate, conf.low, conf.high)
```

    ## Warning: There was 1 warning in `mutate()`.
    ## ℹ In argument: `prop_tests = map2(...)`.
    ## Caused by warning in `prop.test()`:
    ## ! Chi-squared approximation may be incorrect

``` r
city_tests
```

    ## # A tibble: 51 × 4
    ##    city_state      estimate conf.low conf.high
    ##    <chr>              <dbl>    <dbl>     <dbl>
    ##  1 Albuquerque, NM    0.386    0.337     0.438
    ##  2 Atlanta, GA        0.383    0.353     0.415
    ##  3 Baltimore, MD      0.646    0.628     0.663
    ##  4 Baton Rouge, LA    0.462    0.414     0.511
    ##  5 Birmingham, AL     0.434    0.399     0.469
    ##  6 Boston, MA         0.505    0.465     0.545
    ##  7 Buffalo, NY        0.612    0.569     0.654
    ##  8 Charlotte, NC      0.300    0.266     0.336
    ##  9 Chicago, IL        0.736    0.724     0.747
    ## 10 Cincinnati, OH     0.445    0.408     0.483
    ## # ℹ 41 more rows

``` r
# Order cities by estimated proportion unsolved
city_tests_ordered =
  city_tests |>
  arrange(estimate) |>
  mutate(city_state = factor(city_state, levels = city_state))

ggplot(city_tests_ordered, aes(x = city_state, y = estimate)) +
  
  # Dark purple points for the estimate
  geom_point(color = "#4B0082", size = 2.5) +
  
  # Dark purple CI error bars
  geom_errorbar(
    aes(ymin = conf.low, ymax = conf.high),
    width = 0.2,
    color = "#4B0082"
  ) +
  
  # Dashed red horizontal line at 0.50
  geom_hline(
    yintercept = 0.50,
    color = "red",
    linetype = "dashed",
    linewidth = 1
  ) +
  
  coord_flip() +
  labs(
    title = "Proportion of Unsolved Homicides by City",
    x = "City",
    y = "Estimated Proportion Unsolved"
  ) +
  theme_minimal()
```

<img src="p8105_HW5_sp4436_files/figure-gfm/Plot all Cities-1.png" width="90%" />
