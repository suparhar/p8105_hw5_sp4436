---
title: "p8105_hw5_sp4436"
author: "Sukhman Parhar"
date: "2025-11-15"
output: github_document
---

```{r Load Packages and set Themes}
library(tidyverse)
library(readxl)
library(haven)
library(readr)
library(p8105.datasets)
library(ggridges)
library(dplyr)
library(janitor)
library(patchwork)
library(broom)

set.seed(1)

```

## Problem 1

```{r Creating Function}
bday_sim = function(n_room) {
  
  birthdays = sample(1:365, n_room, replace = TRUE)
  
  repeated_bday = length(unique(birthdays)) < n_room
  
  repeated_bday
}

bday_sim(20)
```

```{r Simulation}
bday_results = 
  expand_grid(
    group_size = 2:50,
    iter = 1:10000
  ) |> 
  mutate(
    result = map_lgl(group_size, bday_sim)
  ) |> 
  group_by(group_size) |> 
  summarize(
    prob_repeat = mean(result)
  )
```

```{r Probability Plot}
bday_results |> 
  ggplot(aes(x = group_size, y = prob_repeat)) + 
  geom_point() + 
  geom_line()
```

The probability of at least one shared birthday increases rapidly with group size. Around 23 people, the probability exceeds 50%, and by 50 people it is over 95%. It is nearly zero for small groups (fewer than 10 people) and it rises quickly afterward. 

## Problem 2

```{r Making Function}
sim_one_sample = function(n = 30, true_mu = 0, true_sigma = 5) {
  
#Simulate data
  x = rnorm(n, mean = true_mu, sd = true_sigma)
  
#One-sample t-test of H0: mu = 0
  test_result = t.test(x, mu = 0)
  
#Return estimate + p-value
  broom::tidy(test_result) |>
    select(estimate, p.value)
}
```

```{r Sim}
set.seed(1)
sim_results =
  expand_grid(
    true_mu = 0:6,
    iter = 1:5000
  ) |>
  mutate(
    output = map(true_mu, ~ sim_one_sample(true_mu = .x))
  ) |>
  unnest(output)

sim_results |>
  select(
    true_mu,
    mu_hat = estimate,
    p_value = p.value
  ) |>
  knitr::kable(digits = 3) |>
  head(10)
```

```{r Power Plots}
power_summary = sim_results |>
  mutate(true_mu = as.numeric(true_mu)) |>
  group_by(true_mu) |>
  summarize(power = mean(p.value < 0.05))

power_summary |>
  ggplot(aes(x = true_mu, y = power)) +
  geom_line(linewidth = 1.2, color = "blue") +
  geom_point(size = 3, color = "blue") +

  #Type I error reference line
  geom_hline(yintercept = 0.05, linetype = "longdash", color = "red", linewidth = 1.1) +

  #80% power reference line
  geom_hline(yintercept = 0.80, linetype = "longdash", color = "purple", linewidth = 1.1) +

  labs(
    title = "Statistical Power vs. Effect Size",
    subtitle = "Based on 5,000 simulations per group (n = 30)",
    x = "True Value of μ (Effect Size)",
    y = "Proportion of Times H₀ Rejected (Power)"
  ) +
  theme_minimal()
```

Power increases monotonically as the true mean moves further from 0. As effect size increases, power also increases. When μ = 0, the rejection rate is approximately 0.05, matching the expected Type I error rate. As μ increases, the null hypothesis becomes more false, and the probability of rejection rises.

```{r mu plots}
#Average estimate across all simulations
avg_estimate =
  sim_results |>
  group_by(true_mu) |>
  summarize(mean_estimate = mean(estimate))

#Average estimate conditional on rejection
avg_estimate_reject =
  sim_results |>
  mutate(reject = p.value < 0.05) |>
  group_by(true_mu) |>
  summarize(mean_estimate_reject = mean(estimate[reject]))

#Combine both
combined =
  avg_estimate |>
  left_join(avg_estimate_reject, by = "true_mu")

#Overlay
combined |>
  ggplot(aes(x = true_mu)) +
  
  #Unconditional mean (black)
  geom_line(aes(y = mean_estimate),
            color = "black", linewidth = 1.2) +
  geom_point(aes(y = mean_estimate),
             color = "black", size = 3) +
  
  #Conditional-on-rejection mean (purple)
  geom_line(aes(y = mean_estimate_reject),
            color = "purple", linewidth = 1.2) +
  geom_point(aes(y = mean_estimate_reject),
             color = "purple", size = 3) +
  
  labs(
    title = "Average Estimate of μ vs True μ",
    subtitle = "Black: overall mean estimate; Purple: mean estimate among rejections",
    x = "True μ",
    y = "Average estimate of μ̂"
  ) +
  theme_minimal()
```

The black line shows that the sample mean is an unbiased estimator: across all simulations, the average μ̂ closely matches the true μ. The purple line, which conditions on rejecting the null, is biased upward for small μ because only unusually large samples yield p < 0.05. As μ grows and power approaches 100%, the conditional and unconditional averages converge.

## Problem 3

```{r Load and edit data}
homicide_df = 
  read_csv("https://raw.githubusercontent.com/washingtonpost/data-homicides/master/homicide-data.csv") |>
  janitor::clean_names() |>
  mutate(
    city_state = str_c(city, ", ", state),
    unsolved = disposition %in% c("Closed without arrest", "Open/No arrest")
  )
```

The raw data has 52179 observations with 12 variables: `uid`, `reported_date`, `victim_last`, `victim_first`, `victim_race`, `victim_age`, `victim_sex`, `city`, `state`, `lat`, `lon`, `disposition`. There are 120 NAs between `lat` and `lon`. 

The dataset includes victim demographics (name, age, sex, race), incident date, location (city and state), geographical coordinates, and case disposition. 

```{r Murder numbers}
city_summary =
  homicide_df |>
  group_by(city_state) |>
  summarize(
    total_homicides = n(),
    unsolved_homicides = sum(disposition %in% c("Closed without arrest", "Open/No arrest")),
    .groups = "drop"
  )

knitr::kable(
  city_summary,
  caption = "Total and Unsolved Homicides by City",
  col.names = c("City-State", "Total Homicides", "Unsolved Homicides"),
  digits = 0
)
```

```{r Baltimore ONLY}
#Filter for Baltimore
baltimore_data = city_summary |>
  filter(city_state == "Baltimore, MD")

#Run proportion test using total + unsolved
bal_prop_test = with(baltimore_data, {
  prop.test(
    x = unsolved_homicides, 
    n = total_homicides
  )
})

#Tidy output
bal = broom::tidy(bal_prop_test)

bal
```

```{r}
city_tests =
  city_summary |>
  mutate(
    prop_tests = map2(
      unsolved_homicides,
      total_homicides,
      ~ prop.test(x = .x, n = .y)
    ),
    
    tidy_results = map(prop_tests, broom::tidy)
  ) |>
  unnest(tidy_results) |>
  select(city_state, estimate, conf.low, conf.high)

city_tests
```

```{r Plot all Cities}
#Order cities by estimated proportion unsolved
city_tests_ordered =
  city_tests |>
  arrange(estimate) |>
  mutate(city_state = factor(city_state, levels = city_state))

ggplot(city_tests_ordered, aes(
  x = estimate,
  y = reorder(city_state, estimate))
  ) +
  
  geom_errorbar(
    aes(xmin = conf.low, xmax = conf.high),
    orientation = "y",
    width = 0.15,
    color = "#4B0082",
    linewidth = 0.7
  ) +

  #point estimates
  geom_point(
    size = 1.7,
    color = "#4B0082"
  ) +

  #0.50 reference line
  geom_vline(
    xintercept = 0.50,
    linetype = "dashed",
    color = "red",
    linewidth = 0.9
  ) +

  labs(
    title = "Estimated Proportion of Unsolved Homicides by City",
    x = "Estimated Proportion Unsolved",
    y = "City"
  ) +

  theme_minimal(base_size = 14) +
  theme(
    panel.grid.major.y = element_blank(),
    panel.grid.minor = element_blank(),
    axis.text.y = element_text(size = 10),
    axis.text.x = element_text(size = 11),
    plot.title = element_text(face = "bold", hjust = 0.5)
  )

```

